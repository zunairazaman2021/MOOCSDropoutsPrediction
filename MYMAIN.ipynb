{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zunai\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "importing Jupyter notebook from mymodelD.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import pickle as pkl\n",
    "import time\n",
    "import import_ipynb\n",
    "from mymodelD import CFIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zunai\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "#params: 242433\n",
      "[1] train-result=0.8429, valid-result=0.8420, valid-f1=0.8973 [131.1 s]\n",
      "[2] train-result=0.8451, valid-result=0.8446, valid-f1=0.9007 [133.4 s]\n",
      "[3] train-result=0.8476, valid-result=0.8464, valid-f1=0.9017 [166.1 s]\n",
      "[4] train-result=0.8488, valid-result=0.8479, valid-f1=0.9021 [121.7 s]\n",
      "[5] train-result=0.8489, valid-result=0.8486, valid-f1=0.9012 [120.8 s]\n",
      "Save to path:  my_model/CFIN\n",
      "Time elapsed 674.3013470172882 seconds\n",
      "(0.8486174646890259, array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.04050952, 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.06460387, 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.00212587, 0.        ,\n",
      "        0.        ]], dtype=float32), 0.9012159750111557)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,4'\n",
    "act_feat_basic = pkl.load(open('act_feats.pkl', 'rb'))\n",
    "\n",
    "#user_cat_feat = ['gender', 'cluster_label']\n",
    "user_cat_feat = ['gender','education', 'cluster_label']\n",
    "user_num_feat = ['age', 'user_enroll_num']\n",
    "course_cat_feat = ['course_category']\n",
    "course_num_feat = ['course_enroll_num']\n",
    "\n",
    "\n",
    "def feat_augment(train_feat, test_feat):\n",
    "    act_feats = pkl.load(open('act_feats.pkl', 'rb'))\n",
    "    all_feat = pd.concat([train_feat, test_feat])\n",
    "    all_feat_u_mean = all_feat.groupby('username').mean()[act_feats]\n",
    "    all_feat_u_mean.columns = [x + '#user#mean' for x in all_feat_u_mean.columns]\n",
    "    all_feat_u_max = all_feat.groupby('username').max()[act_feats]\n",
    "    all_feat_u_max.columns = [x + '#user#max' for x in all_feat_u_max.columns]\n",
    "\n",
    "    all_feat = pd.merge(all_feat, all_feat_u_mean, right_index=True, left_on='username')\n",
    "    all_feat = pd.merge(all_feat, all_feat_u_max, right_index=True, left_on='username')\n",
    "\n",
    "    all_feat_c_mean = all_feat.groupby('course_id').mean()[act_feats]\n",
    "    all_feat_c_mean.columns = [x + '#course#mean' for x in all_feat_c_mean.columns]\n",
    "\n",
    "    all_feat_c_max = all_feat.groupby('course_id').max()[act_feats]\n",
    "    all_feat_c_max.columns = [x + '#course#max' for x in all_feat_c_max.columns]\n",
    "\n",
    "    all_feat = pd.merge(all_feat, all_feat_c_mean, right_index=True, left_on='course_id')\n",
    "    all_feat = pd.merge(all_feat, all_feat_c_max, right_index=True, left_on='course_id')\n",
    "\n",
    "    act_feat = []\n",
    "    for f in act_feat_basic:\n",
    "        act_feat.append(f)\n",
    "        act_feat.append(f + '#user#mean')\n",
    "        act_feat.append(f + '#user#max')\n",
    "        act_feat.append(f + '#course#mean')\n",
    "        act_feat.append(f + '#course#max')\n",
    "\n",
    "    return all_feat.loc[train_feat.index], all_feat.loc[test_feat.index], act_feat\n",
    "\n",
    "\n",
    "def dataparse(train, test, num_feat, cat_feat):\n",
    "    all_data = pd.concat([train, test])\n",
    "    feat_dim = 0\n",
    "    feat_dict = dict()\n",
    "    for f in cat_feat:\n",
    "        cat_val = all_data[f].unique()\n",
    "        feat_dict[f] = dict(zip(cat_val, range(feat_dim, len(cat_val) + feat_dim)))\n",
    "        feat_dim += len(cat_val)\n",
    "    for f in num_feat:\n",
    "        feat_dict[f] = feat_dim\n",
    "        feat_dim += 1\n",
    "    data_indice = all_data.copy()\n",
    "    data_value = all_data.copy()\n",
    "    for f in all_data.columns:\n",
    "        if f in num_feat:\n",
    "            data_indice[f] = feat_dict[f]\n",
    "        elif f in cat_feat:\n",
    "            data_indice[f] = data_indice[f].map(feat_dict[f])\n",
    "            data_value[f] = 1.\n",
    "        else:\n",
    "            data_indice.drop(f, axis=1, inplace=True)\n",
    "            data_value.drop(f, axis=1, inplace=True)\n",
    "    return feat_dim, data_indice, data_value\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    dfTrain = pd.read_csv('feat/train_feat.csv', index_col=0)\n",
    "    dfTest = pd.read_csv('feat/test_feat.csv', index_col=0)\n",
    "    dfTrain_u = dfTrain[user_num_feat + user_cat_feat + ['truth']]\n",
    "    dfTest_u = dfTest[user_num_feat + user_cat_feat + ['truth']]\n",
    "\n",
    "    dfTrain_c = dfTrain[course_num_feat + course_cat_feat + ['truth']]\n",
    "    dfTest_c = dfTest[course_num_feat + course_cat_feat + ['truth']]\n",
    "    dfTrain_a = dfTrain[act_feat_basic + ['truth', 'username', 'course_id']]\n",
    "    dfTest_a = dfTest[act_feat_basic + ['truth', 'username', 'course_id']]\n",
    "\n",
    "    return dfTrain_u, dfTest_u, dfTrain_c, dfTest_c, dfTrain_a, dfTest_a\n",
    "\n",
    "\n",
    "def model_run(dfTrain_u, dfTest_u, dfTrain_c, dfTest_c, dfTrain_a, dfTest_a, params, act_feat):\n",
    "    u_feat_dim, u_data_indice, u_data_value = dataparse(dfTrain_u, dfTest_u, user_num_feat, user_cat_feat)\n",
    "    ui_train, uv_train = np.asarray(u_data_indice.loc[dfTrain_u.index], dtype=int), np.asarray(\n",
    "        u_data_value.loc[dfTrain_u.index], dtype=float)\n",
    "    ui_test, uv_test = np.asarray(u_data_indice.loc[dfTest_u.index], dtype=int), np.asarray(\n",
    "        u_data_value.loc[dfTest_u.index], dtype=float)\n",
    "\n",
    "    params[\"u_feat_size\"] = u_feat_dim\n",
    "    params[\"u_field_size\"] = len(ui_train[0])\n",
    "\n",
    "    c_feat_dim, c_data_indice, c_data_value = dataparse(dfTrain_c, dfTest_c, course_num_feat, course_cat_feat)\n",
    "    ci_train, cv_train = np.asarray(c_data_indice.loc[dfTrain_c.index], dtype=int), np.asarray(\n",
    "        c_data_value.loc[dfTrain_c.index], dtype=float)\n",
    "    ci_test, cv_test = np.asarray(c_data_indice.loc[dfTest_c.index], dtype=int), np.asarray(\n",
    "        c_data_value.loc[dfTest_c.index], dtype=float)\n",
    "\n",
    "    params[\"c_feat_size\"] = c_feat_dim\n",
    "    params[\"c_field_size\"] = len(ci_train[0])\n",
    "\n",
    "    av_train = np.asarray(dfTrain_a[act_feat], dtype=float)\n",
    "\n",
    "    ai_train = np.asarray([range(len(act_feat)) for x in range(len(dfTrain_a))], dtype=int)\n",
    "    av_test = np.asarray(dfTest_a[act_feat], dtype=float)\n",
    "    ai_test = np.asarray([range(len(act_feat)) for x in range(len(dfTest_a))], dtype=int)\n",
    "\n",
    "    params[\"a_feat_size\"] = len(ai_train[0])\n",
    "    params[\"a_field_size\"] = len(ai_train[0])\n",
    "\n",
    "    y_train = np.asarray(dfTrain_a['truth'], dtype=int)\n",
    "    y_test = np.asarray(dfTest_a['truth'], dtype=int)\n",
    "    model = CFIN(**params)\n",
    "\n",
    "    # generate valid set\n",
    "    train_num = len(y_train)\n",
    "    indices = np.arange(train_num)\n",
    "    np.random.shuffle(indices)\n",
    "    split_ = int(0.8 * train_num)\n",
    "    ui_train_, ui_valid = ui_train[indices][:split_], ui_train[indices[split_:]]\n",
    "    uv_train_, uv_valid = uv_train[indices][:split_], uv_train[indices[split_:]]\n",
    "    ci_train_, ci_valid = ci_train[indices][:split_], ci_train[indices[split_:]]\n",
    "    cv_train_, cv_valid = cv_train[indices][:split_], cv_train[indices[split_:]]\n",
    "    ai_train_, ai_valid = ai_train[indices][:split_], ai_train[indices[split_:]]\n",
    "    av_train_, av_valid = av_train[indices[:split_]], av_train[indices[split_:]]\n",
    "    y_train_, y_valid = y_train[indices[:split_]], y_train[indices[split_:]]\n",
    "\n",
    "    # model selection\n",
    "    \"\"\"\n",
    "    best_epoch = model.fit(ui_train_, uv_train_, ci_train_, cv_train_, ai_train_, av_train_, y_train_, ui_valid, uv_valid, ci_valid, cv_valid, ai_valid, av_valid, y_valid)\n",
    "    params['epoch'] = best_epoch\n",
    "    model = CFIN(**params)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    # train\n",
    "    model.fit(ui_train, uv_train, ci_train, cv_train, ai_train, av_train, y_train, ui_test, uv_test, ci_test, cv_test,\n",
    "              ai_test, av_test, y_test, early_stopping=False)\n",
    "    print(\"Time elapsed {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    # prediction results on test set\n",
    "    # model.evaluate(ui_test, uv_test, ci_test, cv_test, ai_test, av_test, y_test)\n",
    "    print(model.evaluate(ui_test, uv_test, ci_test, cv_test, ai_test, av_test, y_test))\n",
    "\n",
    "\n",
    "# load data\n",
    "dfTrain_u, dfTest_u, dfTrain_c, dfTest_c, dfTrain_a, dfTest_a = load_data()\n",
    "dfTrain_a, dfTest_a, act_feat = feat_augment(dfTrain_a, dfTest_a)\n",
    "\n",
    "params = {\n",
    "    \"embedding_size\": 32,\n",
    "    \"attn_size\": 16,\n",
    "    \"conv_size\": 512,\n",
    "    \"context_size\": 32,\n",
    "    \"deep_layers\": [256],\n",
    "    \"dropout_deep\": [0.9, 0.9],\n",
    "    \"dropout_attn\": [1.],\n",
    "    \"activation\": tf.nn.relu,\n",
    "    \"epoch\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.00001,\n",
    "    \"verbose\": True,\n",
    "    \"attn\": True,\n",
    "    \"eval_metric\": roc_auc_score,\n",
    "    \"random_seed\": 12345\n",
    "}\n",
    "\n",
    "# y_train_dfm, y_test_dfm = model_run(dfTrain_u, dfTest_u, dfTrain_c, dfTest_c, dfTrain_a, dfTest_a,params, act_feat)\n",
    "model_run(dfTrain_u, dfTest_u, dfTrain_c, dfTest_c, dfTrain_a, dfTest_a, params, act_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
